{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80105dd",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.naukri.com/\n",
    "Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0294da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0d0c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# search for searchjob_tag\n",
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_job\n",
    "\n",
    "#placing the data in job search\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# search for the location bar\n",
    "search_loc = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "\n",
    "#locating the data in search location \n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#getting the  submit button link\n",
    "search_btn =driver.find_element_by_class_name('qsbSubmit')\n",
    "\n",
    "#click on the submit button\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fc50e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proficient in Cisco system posting and / or distribution of reporting as defined or req...',\n",
       " 'Experience in handling large data volumes. Strong skills in SQL coding writing complex ...',\n",
       " 'Understands the underlying business problem to define the required data and appropriate...',\n",
       " 'About the role:Data Analyst is an Individual Contributor role where you will be respons...',\n",
       " 'Strong knowledge of and experience with reporting tools such as Tableau, Google Looker,...',\n",
       " 'This role will provide YOU the opportunity to lead key activities to progress YOUR care...',\n",
       " 'The candidate will be required to interface with various business strategy and executio...',\n",
       " 'Individual must be organized, dependable, able to multi-task and manage priorities, dis...',\n",
       " 'Freshers are welcomeAny certification on Excel is preferred Should be diligent, hard-wo...',\n",
       " 'Perform data-mining and analysis using tools including MS Excel, MySQL, SQL, Python and...',\n",
       " 'Bachelors degree in Management of Information Systems (MIS), Mathematics, Statistics, C...',\n",
       " 'Accountable for external client relationship Manage complex client projects in environm...',\n",
       " 'Job Purpose Shell is implementing Data Cataloguing throughout the organization. As the ...',\n",
       " 'Experience in data mining techniques and methodologies (data prep / modeling, classific...',\n",
       " 'A minimum of 3 years of experience in the field of Data Analysis, Data VisualizationSki...',\n",
       " 'Pull data required to conduct business analysis, build reports, dashboards and metrics ...',\n",
       " 'Individual must be organized, dependable, able to multi-task and manage priorities, dis...',\n",
       " 'First and foremost, use first principles thinking, data and analytical skills to genera...',\n",
       " 'We are seeking a Marketing Data Analyst who will deliver insights to the broader market...',\n",
       " 'These checks and reviews are made in strict accordance with regulatory requirement and ...']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the details\n",
    "#getting the title web elements\n",
    "\n",
    "tle_t = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "# extracting only 10 web elements\n",
    "title = []\n",
    "for i in tle_t:\n",
    "    title.append(i.text)\n",
    "title\n",
    "\n",
    "# extracting webelement of company name\n",
    "compny_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Converting webelements into text format\n",
    "company = []\n",
    "for i in compny_tag:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "exp = driver.find_elements_by_xpath('//span[contains (@title,\"Yrs\")]')\n",
    "#collecting only 10 web elements\n",
    "experience = []\n",
    "for i in exp:\n",
    "    experience.append(i.text)\n",
    "experience\n",
    "\n",
    "#extracting the salary_tag web elements\n",
    "sal = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "#collecting only 10 web elements\n",
    "salary = []\n",
    "for i in sal:\n",
    "    salary.append(i.text)\n",
    "salary    \n",
    "\n",
    "#extracting the location_tag web elements\n",
    "loc = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location = []\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "location\n",
    "\n",
    "#extracting the description web elements\n",
    "dis = driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "#converting web elements into text format\n",
    "discription = []\n",
    "for i in dis:\n",
    "    discription.append(i.text)\n",
    "discription   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29d027b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Discription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA Data Analyst</td>\n",
       "      <td>Ralph Lauren</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Proficient in Cisco system posting and / or di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Experience in handling large data volumes. Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Ericsson Global Services</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Understands the underlying business problem to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the role:Data Analyst is an Individual C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst - Data Modeling/Database D...</td>\n",
       "      <td>K &amp; R Enterprises</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Strong knowledge of and experience with report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>GSK India</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>This role will provide YOU the opportunity to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GSK India</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The candidate will be required to interface wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Individual must be organized, dependable, able...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aldius Consulting Services Pvt Ltd (Paramantra)</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>2,00,000 - 3,50,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Freshers are welcomeAny certification on Excel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OYO Rooms - Data Analyst / Business Analyst</td>\n",
       "      <td>OyoRooms</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Perform data-mining and analysis using tools i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                                    QA Data Analyst   \n",
       "1                                Senior Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4  Senior Data Analyst - Data Modeling/Database D...   \n",
       "5                                       Data analyst   \n",
       "6                                       Data Analyst   \n",
       "7                             Financial Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9        OYO Rooms - Data Analyst / Business Analyst   \n",
       "\n",
       "                                      Company_name Experience  \\\n",
       "0                                     Ralph Lauren    0-3 Yrs   \n",
       "1                                         Flipkart    4-6 Yrs   \n",
       "2                         Ericsson Global Services  10-20 Yrs   \n",
       "3                                         Flipkart    1-6 Yrs   \n",
       "4                                K & R Enterprises    4-6 Yrs   \n",
       "5                                        GSK India    5-9 Yrs   \n",
       "6                                        GSK India   7-10 Yrs   \n",
       "7                                          Moody's    0-2 Yrs   \n",
       "8  Aldius Consulting Services Pvt Ltd (Paramantra)    0-2 Yrs   \n",
       "9                                         OyoRooms    2-6 Yrs   \n",
       "\n",
       "                    Salary                                           Location  \\\n",
       "0            Not disclosed                                Bangalore/Bengaluru   \n",
       "1            Not disclosed                                Bangalore/Bengaluru   \n",
       "2            Not disclosed                                Bangalore/Bengaluru   \n",
       "3            Not disclosed                                Bangalore/Bengaluru   \n",
       "4            Not disclosed                                Bangalore/Bengaluru   \n",
       "5            Not disclosed                                Bangalore/Bengaluru   \n",
       "6            Not disclosed                                Bangalore/Bengaluru   \n",
       "7            Not disclosed                                Bangalore/Bengaluru   \n",
       "8  2,00,000 - 3,50,000 PA.                                Bangalore/Bengaluru   \n",
       "9            Not disclosed  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "\n",
       "                                         Discription  \n",
       "0  Proficient in Cisco system posting and / or di...  \n",
       "1  Experience in handling large data volumes. Str...  \n",
       "2  Understands the underlying business problem to...  \n",
       "3  About the role:Data Analyst is an Individual C...  \n",
       "4  Strong knowledge of and experience with report...  \n",
       "5  This role will provide YOU the opportunity to ...  \n",
       "6  The candidate will be required to interface wi...  \n",
       "7  Individual must be organized, dependable, able...  \n",
       "8  Freshers are welcomeAny certification on Excel...  \n",
       "9  Perform data-mining and analysis using tools i...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame\n",
    "data= pd.DataFrame({'Job_Title':title[:10],\n",
    "                   'Company_name':company[:10],\n",
    "                   'Experience':experience[:10],\n",
    "                   'Salary':salary[:10],\n",
    "                   'Location':location[:10],\n",
    "                   'Discription':discription[:10]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd926c",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c7b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# search for searchjob_tag\n",
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "\n",
    "#placing the data in job search\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# search for the location bar\n",
    "search_loc = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "\n",
    "#locating the data in search location \n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#getting the  submit button link\n",
    "search_btn =driver.find_element_by_class_name('qsbSubmit')\n",
    "\n",
    "#click on the submit button\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361d9d4",
   "metadata": {},
   "source": [
    "# Extracting the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d001e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Discription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Tax Automation &amp; Operations - Data Scie...</td>\n",
       "      <td>Dell</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As you develop in this role, and become more f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst / Data Scientist</td>\n",
       "      <td>MilliporeSigma</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bachelor s Degree in Computer Science / Statis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>You have a masters degree in information techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Sabre</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities Work with subject matter expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist (Fintech)</td>\n",
       "      <td>NIRA</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>25,00,000 - 35,00,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Company: NIRA Senior Data ScientistRoles &amp; Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Shell</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Experience in developing end-to-end models usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Lead / Architect - Looking Fo...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Pune, Gurgaon/Gurugram,...</td>\n",
       "      <td>PhD / Masters in Computer Science / Statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Lead / Architect - Looking Fo...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>PhD / Masters in Computer Science / Statistics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title    Company_name  \\\n",
       "0  Global Tax Automation & Operations - Data Scie...            Dell   \n",
       "1                           Analyst / Data Scientist  MilliporeSigma   \n",
       "2                 Data Scientist: Advanced Analytics             IBM   \n",
       "3                 Data Scientist: Advanced Analytics             IBM   \n",
       "4                              Senior Data Scientist         Siemens   \n",
       "5                              Senior Data Scientist           Sabre   \n",
       "6                    Senior Data Scientist (Fintech)            NIRA   \n",
       "7                              Senior Data Scientist           Shell   \n",
       "8  Data Scientist - Lead / Architect - Looking Fo...           Wipro   \n",
       "9  Data Scientist - Lead / Architect - Looking Fo...           Wipro   \n",
       "\n",
       "  Experience                     Salary  \\\n",
       "0    3-5 Yrs              Not disclosed   \n",
       "1    2-5 Yrs              Not disclosed   \n",
       "2   5-10 Yrs              Not disclosed   \n",
       "3    2-5 Yrs              Not disclosed   \n",
       "4    3-8 Yrs              Not disclosed   \n",
       "5    3-5 Yrs              Not disclosed   \n",
       "6    4-6 Yrs  25,00,000 - 35,00,000 PA.   \n",
       "7   6-11 Yrs              Not disclosed   \n",
       "8   5-10 Yrs              Not disclosed   \n",
       "9   5-10 Yrs              Not disclosed   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                       Chennai, Bangalore/Bengaluru   \n",
       "8  Kochi/Cochin, Kolkata, Pune, Gurgaon/Gurugram,...   \n",
       "9  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "\n",
       "                                         Discription  \n",
       "0  As you develop in this role, and become more f...  \n",
       "1  Bachelor s Degree in Computer Science / Statis...  \n",
       "2  As a Data Scientist at IBM, you will help tran...  \n",
       "3  As a Data Scientist at IBM, you will help tran...  \n",
       "4  You have a masters degree in information techn...  \n",
       "5  Responsibilities Work with subject matter expe...  \n",
       "6  Company: NIRA Senior Data ScientistRoles & Res...  \n",
       "7  Experience in developing end-to-end models usi...  \n",
       "8  PhD / Masters in Computer Science / Statistics...  \n",
       "9  PhD / Masters in Computer Science / Statistics...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title\n",
    "\n",
    "tle_t = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "title = []\n",
    "for i in tle_t:\n",
    "    title.append(i.text)\n",
    "title\n",
    "\n",
    "#Company_name\n",
    "company = []\n",
    "company_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#experience\n",
    "exp = driver.find_elements_by_xpath('//span[contains (@title,\"Yrs\")]')\n",
    "experience = []\n",
    "for i in exp:\n",
    "    experience.append(i.text)\n",
    "experience\n",
    "\n",
    "#extracting the salary_tag web elements\n",
    "sal = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "salary = []\n",
    "for i in sal:\n",
    "    salary.append(i.text)\n",
    "salary\n",
    "\n",
    "#extracting the location_tag web elements\n",
    "loc = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location = []\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "location\n",
    "\n",
    "#extracting the description web elements\n",
    "dis = driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "discription = []\n",
    "for i in dis:\n",
    "    discription.append(i.text)\n",
    "#discription\n",
    "\n",
    "# DataFrame\n",
    "data= pd.DataFrame({'Job_Title':title[:10],\n",
    "                   'Company_name':company[:10],\n",
    "                   'Experience':experience[:10],\n",
    "                   'Salary':salary[:10],\n",
    "                   'Location':location[:10],\n",
    "                   'Discription':discription[:10]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad5728",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b86a3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# search for searchjob_tag\n",
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "\n",
    "#placing the data in job search\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#getting the  submit button link\n",
    "search_btn =driver.find_element_by_class_name('qsbSubmit')\n",
    "\n",
    "#click on the submit button\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa28eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking filter by selecting location check_box using absoulte path\n",
    "search_loc = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/p\")\n",
    "search_loc.click()\n",
    "\n",
    "\n",
    "# clicking filter by selecting check boxes using absoulte path\n",
    "salary_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/p\")\n",
    "salary_check.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b206ed",
   "metadata": {},
   "source": [
    "# Extracting the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f09ae746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NAVIKENZ INDIA PRIVATE LIMITED</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist-Onsite and offshore</td>\n",
       "      <td>PROKXIMITY</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist | A Fintech Organisation</td>\n",
       "      <td>Vision Beyond Resources India Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>5,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>4,75,000 - 9,75,000 PA.</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CHANGE LEADERS CONSULTING</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DECISION POINT PRIVATE LIMITED</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Alp Consulting Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data &amp; Applied Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data and applied Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>New Delhi, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job_Title  \\\n",
       "0                           Data Scientist   \n",
       "1       Data Scientist-Onsite and offshore   \n",
       "2  Data Scientist | A Fintech Organisation   \n",
       "3               Data Scientist (freelance)   \n",
       "4                           Data Scientist   \n",
       "5                           Data Scientist   \n",
       "6                           Data Scientist   \n",
       "7                 Data & Applied Scientist   \n",
       "8               Data and applied Scientist   \n",
       "9                           Data Scientist   \n",
       "\n",
       "                                    Company_name Experience  \\\n",
       "0                 NAVIKENZ INDIA PRIVATE LIMITED    2-5 Yrs   \n",
       "1                                     PROKXIMITY    3-8 Yrs   \n",
       "2  Vision Beyond Resources India Private Limited    2-7 Yrs   \n",
       "3                                          2Coms    2-7 Yrs   \n",
       "4                      CHANGE LEADERS CONSULTING    3-8 Yrs   \n",
       "5                 DECISION POINT PRIVATE LIMITED    1-6 Yrs   \n",
       "6                         Alp Consulting Limited    1-6 Yrs   \n",
       "7                                      Microsoft    3-7 Yrs   \n",
       "8                                      Microsoft    3-7 Yrs   \n",
       "9       Cloudstrats Technologies Private Limited    3-5 Yrs   \n",
       "\n",
       "                     Salary                                           Location  \n",
       "0             Not disclosed  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...  \n",
       "1             Not disclosed  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "2  5,00,000 - 15,00,000 PA.                                   Gurgaon/Gurugram  \n",
       "3   4,75,000 - 9,75,000 PA.                                   New Delhi, Delhi  \n",
       "4             Not disclosed                                          New Delhi  \n",
       "5             Not disclosed      Gurgaon/Gurugram, Chennai\\n(WFH during Covid)  \n",
       "6             Not disclosed  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...  \n",
       "7             Not disclosed  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "8             Not disclosed  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "9             Not disclosed         New Delhi, Delhi / NCR, Mumbai (All Areas)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title\n",
    "tle_t = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "title = []\n",
    "for i in tle_t:\n",
    "    title.append(i.text)\n",
    "title\n",
    "\n",
    "#company name\n",
    "company_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company = []\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#experience\n",
    "exp = driver.find_elements_by_xpath('//span[contains (@title,\"Yrs\")]')\n",
    "experience = []\n",
    "for i in exp:\n",
    "    experience.append(i.text)\n",
    "experience\n",
    "\n",
    "#salary\n",
    "sal = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "salary = []\n",
    "for i in sal:\n",
    "    salary.append(i.text)\n",
    "salary\n",
    "\n",
    "#location\n",
    "loc = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location = []\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "location\n",
    "\n",
    "#DataFrame\n",
    "\n",
    "data= pd.DataFrame({'Job_Title':title[:10],\n",
    "                   'Company_name':company[:10],\n",
    "                   'Experience':experience[:10],\n",
    "                   'Salary':salary[:10],\n",
    "                   'Location':location[:10],\n",
    "                   })\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaf02b",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "Brand\n",
    "Product Description\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fb65111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#closing the popup\n",
    "popup_btn =driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "popup_btn.click()\n",
    "\n",
    "#search bar web element\n",
    "search = driver.find_element_by_class_name(\"_3704LK \")\n",
    "search\n",
    "\n",
    "# entering the search option\n",
    "search.send_keys('sunglasses')\n",
    "\n",
    "#getting the webelements of the search icon\n",
    "search_btn =driver.find_element_by_class_name('L0Z3Pu')\n",
    "\n",
    "#click on the search button\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333f73a",
   "metadata": {},
   "source": [
    "# Extracting the data from the resultant search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11e45d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_title</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Product_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, UV Protection, Gradient, Riding Gla...</td>\n",
       "      <td>₹229</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹1,483</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Riding Glasses Wayfarer Sunglas...</td>\n",
       "      <td>₹159</td>\n",
       "      <td>91% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>92% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹234</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (62)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹221</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹579</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>agera</td>\n",
       "      <td>Gradient Aviator Sunglasses (55)</td>\n",
       "      <td>₹186</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Riding Glasses Rectangular Sung...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product_title                                Product_description  \\\n",
       "0     CRYSTAL CART  Polarized, UV Protection, Gradient, Riding Gla...   \n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "2           GANSTA  UV Protection, Riding Glasses Wayfarer Sunglas...   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)   \n",
       "4           GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "..             ...                                                ...   \n",
       "95  ROZZETTA CRAFT              UV Protection Aviator Sunglasses (62)   \n",
       "96          SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...   \n",
       "97        Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "98           agera                   Gradient Aviator Sunglasses (55)   \n",
       "99  ROZZETTA CRAFT  UV Protection, Riding Glasses Rectangular Sung...   \n",
       "\n",
       "   Product_Price Product_offer  \n",
       "0           ₹229       84% off  \n",
       "1         ₹1,483       40% off  \n",
       "2           ₹159       91% off  \n",
       "3           ₹198       92% off  \n",
       "4           ₹234       88% off  \n",
       "..           ...           ...  \n",
       "95          ₹599       76% off  \n",
       "96          ₹221       86% off  \n",
       "97          ₹579       27% off  \n",
       "98          ₹186       83% off  \n",
       "99          ₹399       82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "title = []\n",
    "description = []\n",
    "cost = []\n",
    "offer = []\n",
    "\n",
    "for i in range(3):\n",
    "    #print(\"page :\",(i+1))\n",
    "    titles = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in titles:\n",
    "          title.append(i.text)\n",
    "    description_s = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for i in description_s:\n",
    "        description.append(i.text)\n",
    "    cost_s = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in cost_s:\n",
    "        cost.append(i.text)\n",
    "    offer_s = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in offer_s:\n",
    "        offer.append(i.text)\n",
    "        \n",
    "    # getting in to next page to collect the data\n",
    "    next_page = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    next_page.click()\n",
    "    sleep(2)\n",
    "\n",
    "#DataFrame\n",
    "data = pd.DataFrame({'Product_title':title[:100],\n",
    "                    'Product_description':description[:100],\n",
    "                    'Product_Price':cost[:100],\n",
    "                    'Product_offer':offer[:100]})\n",
    "data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a58bf2",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "raw",
   "id": "774d0fa4",
   "metadata": {},
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb195e75",
   "metadata": {},
   "source": [
    "#Rating\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"page :\",(i+1))\n",
    "    count=0\n",
    "    if (count!=100):\n",
    "        rating_s = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        \n",
    "        # printing text elements under the webelements\n",
    "        \n",
    "        for r in rating_s:\n",
    "            rating.append(r.text)\n",
    "        \n",
    "    # getting in to next page to collect the data        \n",
    "        next_page = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "        next_page.click()\n",
    "        sleep(3)\n",
    "        count=+1\n",
    "    \n",
    "    else:\n",
    "        exit()\n",
    "   # extracting 100 elements from the resultants\n",
    "\n",
    "rating\n",
    "\n",
    "#reviewsummary \n",
    "\n",
    "review_summ = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"page :\",(i+1))\n",
    "    count=0\n",
    "    if (count!=100):\n",
    "        review_s = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        \n",
    "        # printing text elements under the webelements\n",
    "        \n",
    "        for r in review_s:\n",
    "            review_summ.append(r.text)\n",
    "        \n",
    "    # getting in to next page to collect the data        \n",
    "        next_page = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "        next_page.click()\n",
    "        sleep(3)\n",
    "        count=+1\n",
    "    \n",
    "    else:\n",
    "        exit()\n",
    "   # extracting 100 elements from the resultants\n",
    "\n",
    "review_summ\n",
    "\n",
    "#full Description\n",
    "full_desc = []\n",
    "for i in range(10):\n",
    "    print(\"page :\",(i+1))\n",
    "    count=0\n",
    "    if (count!=100):\n",
    "        full_d = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        \n",
    "        # printing text elements under the webelements\n",
    "        \n",
    "        for f in full_d:\n",
    "            full_desc.append(f.text)\n",
    "        \n",
    "    # getting in to next page to collect the data        \n",
    "        next_page = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "        next_page.click()\n",
    "        sleep(3)\n",
    "        count=+1\n",
    "    \n",
    "    else:\n",
    "        exit()\n",
    "   # extracting 100 elements from the resultants\n",
    "\n",
    "full_desc\n",
    "\n",
    "data = pd.DataFrame({'Rating':rating,\n",
    "                    'Review Summary':review_summ,\n",
    "                    'Full_review':full_desc})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92e78b",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa48d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#closing the popup\n",
    "popup_btn =driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "popup_btn.click()\n",
    "\n",
    "#search bar web element\n",
    "search = driver.find_element_by_class_name(\"_3704LK \")\n",
    "\n",
    "#sending search key\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#click on the search button\n",
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c02039",
   "metadata": {},
   "source": [
    "# Extracting webelements \"Name\",\"Description\",\"Price\" and \"offer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbd52ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Product_price</th>\n",
       "      <th>Product_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Echor Men's Sneakers Fashion Lightweight Runni...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Stylish &amp; Trendy Shoe For Men Sneakers Sneaker...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹209</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elevarse</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "      <td>₹374</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Castoes</td>\n",
       "      <td>white Casual shoes,Sneakers for men's Sneakers...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹327</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Perfect Sports Shoes for Men's Running ,Cyclin...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Name                                Product_description  \\\n",
       "0         Echor  Echor Men's Sneakers Fashion Lightweight Runni...   \n",
       "1         Echor  Stylish & Trendy Shoe For Men Sneakers Sneaker...   \n",
       "2        BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "3      Elevarse  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...   \n",
       "4        BRUTON  STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...   \n",
       "..          ...                                                ...   \n",
       "95      Castoes  white Casual shoes,Sneakers for men's Sneakers...   \n",
       "96    SCATCHITE                                   Sneakers For Men   \n",
       "97   D-SNEAKERZ                                   Sneakers For Men   \n",
       "98       Chevit                                   Sneakers For Men   \n",
       "99        Echor  Perfect Sports Shoes for Men's Running ,Cyclin...   \n",
       "\n",
       "   Product_price Product_offer  \n",
       "0           ₹449       70% off  \n",
       "1           ₹449       70% off  \n",
       "2           ₹209       83% off  \n",
       "3           ₹299       70% off  \n",
       "4           ₹374       89% off  \n",
       "..           ...           ...  \n",
       "95          ₹419       62% off  \n",
       "96          ₹327       62% off  \n",
       "97          ₹249       70% off  \n",
       "98          ₹599       70% off  \n",
       "99          ₹449       69% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "descr = []\n",
    "price =[]\n",
    "offer =[]\n",
    "\n",
    "for i in range(3):\n",
    "    #print(\"page :\",(i+1))\n",
    "    #Name\n",
    "    name_s = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for r in name_s:\n",
    "        name.append(r.text)\n",
    "    \n",
    "    #Description\n",
    "    des_t = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for r in des_t:\n",
    "        descr.append(r.text)    \n",
    "    \n",
    "    #Price\n",
    "    price_p= driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for r in price_p:\n",
    "        price.append(r.text)\n",
    "    \n",
    "    #Offers\n",
    "    offer_p= driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for r in offer_p:\n",
    "        offer.append(r.text)\n",
    "    \n",
    "    \n",
    "    # getting in to next page to collect the data        \n",
    "    next_page = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    next_page.click()\n",
    "    sleep(3)\n",
    "\n",
    "data = pd.DataFrame({'Product_Name':name[:100],\n",
    "                    'Product_description':descr[:100],\n",
    "                    'Product_price':price[:100],\n",
    "                    'Product_offer':offer[:100]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7b730",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19822ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "driver.maximize_window() #maximise window\n",
    "\n",
    "# sending URL to webdriver\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)\n",
    "\n",
    "# selecting the price check box\n",
    "price_check = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_check.click()\n",
    "\n",
    "#selecting color check box\n",
    "color_check = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]')\n",
    "color_check.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914886d",
   "metadata": {},
   "source": [
    "# Extracting shoes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16162088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 1\n",
      "page: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Winflo 7 Running Shoes</td>\n",
       "      <td>Rs. 7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Air Max Dawn Sneakers</td>\n",
       "      <td>Rs. 10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Blazer Court Skateboarding</td>\n",
       "      <td>Rs. 7495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Jamming 2.0 Running Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Deviate Nitro Running Shoe</td>\n",
       "      <td>Rs. 10499Rs. 14999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                     Description                        Price\n",
       "0            Nike      Men Winflo 7 Running Shoes                     Rs. 7995\n",
       "1            Nike       Men Air Max Dawn Sneakers                    Rs. 10995\n",
       "2            Nike  Men Blazer Court Skateboarding                     Rs. 7495\n",
       "3          Clarks      Men Leather Formal Loafers                     Rs. 7499\n",
       "4  Tommy Hilfiger            Men Leather Sneakers                     Rs. 7999\n",
       "5            Puma   Men Jamming 2.0 Running Shoes                    Rs. 12999\n",
       "6            Puma               Men Running Shoes                    Rs. 12999\n",
       "7            Puma       Men Magnify Nitro Running   Rs. 7799Rs. 12999(40% OFF)\n",
       "8            Puma  Men Deviate Nitro Running Shoe  Rs. 10499Rs. 14999(30% OFF)\n",
       "9  Tommy Hilfiger            Men Leather Sneakers                     Rs. 7999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand =[]\n",
    "desc=[]\n",
    "price =[]\n",
    "\n",
    "for i in range(2):\n",
    "    #print(\"page:\",(i+1))\n",
    "    #brand\n",
    "    shoe_b =driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    for s in shoe_b:\n",
    "        brand.append(s.text)\n",
    "    \n",
    "    #description    \n",
    "    shoe_des =driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for s in shoe_des:\n",
    "        desc.append(s.text)\n",
    "    \n",
    "    #Price\n",
    "    shoe_p =driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for s in shoe_p:\n",
    "        price.append(s.text) \n",
    "    \n",
    "    next_page =driver.find_element_by_xpath('//li[@class=\"pagination-next\"]')\n",
    "    next_page.click()\n",
    "    sleep(3)\n",
    "\n",
    "#DataFrame\n",
    "data = pd.DataFrame({})\n",
    "\n",
    "data['Brand']=brand[:10]\n",
    "data['Description']=desc[:10]\n",
    "data['Price']=price[:10]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef468d",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image: After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "Title\n",
    "Ratings\n",
    "Price As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec74fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell New 15 PQC-N5030 Intel Inspiron 3510 15.6...</td>\n",
       "      <td>17</td>\n",
       "      <td>34,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Inspiron 3501 15.6 inches FHD Display Lap...</td>\n",
       "      <td>58</td>\n",
       "      <td>57,125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell New 15 PQC-N5030 Intel Inspiron 3510 15.6...</td>\n",
       "      <td>17</td>\n",
       "      <td>34,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Intel Pentium Quad Core 15.6 inches Busin...</td>\n",
       "      <td>26</td>\n",
       "      <td>28,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 3502 15.6 inches HD Display Lapt...</td>\n",
       "      <td>462</td>\n",
       "      <td>29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Extensa 15 Thin &amp; Light Intel Processor P...</td>\n",
       "      <td>409</td>\n",
       "      <td>32,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Pentium Silver - (8 GB/256 GB SSD/Windows...</td>\n",
       "      <td>58</td>\n",
       "      <td>57,125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Inspiron 3501 15.6 inches FHD Display Lap...</td>\n",
       "      <td>137</td>\n",
       "      <td>28,630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Pentium Quad Core - (4 GB/1 TB HDD/Window...</td>\n",
       "      <td>100</td>\n",
       "      <td>50,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 14 Intel Pentium N6000 14-inch(35.6 cm) Lap...</td>\n",
       "      <td>1</td>\n",
       "      <td>31,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating   Price\n",
       "0  Dell New 15 PQC-N5030 Intel Inspiron 3510 15.6...     17  34,390\n",
       "1  Dell Inspiron 3501 15.6 inches FHD Display Lap...     58  57,125\n",
       "2  Dell New 15 PQC-N5030 Intel Inspiron 3510 15.6...     17  34,390\n",
       "3  ASUS Intel Pentium Quad Core 15.6 inches Busin...     26  28,990\n",
       "4  Dell Inspiron 3502 15.6 inches HD Display Lapt...    462  29,990\n",
       "5  Acer Extensa 15 Thin & Light Intel Processor P...    409  32,990\n",
       "6  ASUS Pentium Silver - (8 GB/256 GB SSD/Windows...     58  57,125\n",
       "7  Dell Inspiron 3501 15.6 inches FHD Display Lap...    137  28,630\n",
       "8  ASUS Pentium Quad Core - (4 GB/1 TB HDD/Window...    100  50,490\n",
       "9  HP 14 Intel Pentium N6000 14-inch(35.6 cm) Lap...      1  31,490"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with the driver\n",
    "\n",
    "drive = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver\")\n",
    "drive.maximize_window()\n",
    "#drive\n",
    "\n",
    "#sending url to webdriver\n",
    "url = 'https://www.amazon.in/'\n",
    "drive.get(url)\n",
    "\n",
    "#getting  the search bar web element\n",
    "search = drive.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "#search\n",
    "\n",
    "#sending search key\n",
    "\n",
    "search.send_keys('Laptop')\n",
    "\n",
    "search_btn=drive.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div')\n",
    "search_btn.click()\n",
    "\n",
    "#selecting check box\n",
    "intel7_check =drive.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[3]/li[12]/span/a/span')\n",
    "intel7_check.click()\n",
    "\n",
    "#Title\n",
    "\n",
    "title = []\n",
    "t = drive.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in t:\n",
    "    title.append(i.text)\n",
    "title[:10]\n",
    "\n",
    "#Rating\n",
    "rating = []\n",
    "r = drive.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]')\n",
    "\n",
    "for i in r:\n",
    "    #print(i)\n",
    "    rating.append(i.text)\n",
    "    \n",
    "#price\n",
    "price = []\n",
    "p= drive.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "\n",
    "for i in p:\n",
    "    price.append(i.text)\n",
    "    \n",
    "#data Frame making\n",
    "laptop = pd.DataFrame({})\n",
    "laptop['Title']=title[:10]\n",
    "laptop['Rating']=rating[:10]\n",
    "laptop['Price']=price[:10]\n",
    "laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acca861",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "Click on the Job option as shown in the image\n",
    "After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button. ASSIGNMENT 2\n",
    "You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53055ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#sending the url\n",
    "\n",
    "url =' https://www.ambitionbox.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#clicking on the job option\n",
    "\n",
    "job_click = driver.find_element_by_xpath('//a[@class=\"link jobs\"]')\n",
    "job_click.click()\n",
    "\n",
    "#scraping the web elements of search key\n",
    "\n",
    "job_search = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input')\n",
    "job_search\n",
    "\n",
    "#sending the search key\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#click on the search button\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button')\n",
    "search_btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "121237c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the job search location\n",
    "search_loc = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "search_loc.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48576435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending the search location\n",
    "search_loc_enter = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search_loc_enter.send_keys('Noida')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6125b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the location \"Noida\"\n",
    "select = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "select.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19e5618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company_info</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Delhi NCR, Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS - Assistant Director - Data Science - A...</td>\n",
       "      <td>EY GDS</td>\n",
       "      <td>Bengaluru/Bangalore, Noida, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Opportunity | Tavant India</td>\n",
       "      <td>Tavant Technologies India Pvt. Ltd.</td>\n",
       "      <td>Bengaluru/Bangalore, Hyderabad/Secunderabad, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking For Senior Data Scientist For Denave</td>\n",
       "      <td>Denave India Pvt Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Assistant Manager</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Bengaluru/Bangalore +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CogniTensor - Data Scientist (1-2 yrs)</td>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist | Data Engineer | Machine Learning</td>\n",
       "      <td>Pitney Bowes India Pvt ltd</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>Zyoin</td>\n",
       "      <td>Bengaluru/Bangalore, Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manager Data Scientist</td>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1      Urgent Requirement || Data Scientist || Noida   \n",
       "2  EY GDS - Assistant Director - Data Science - A...   \n",
       "3                         Opportunity | Tavant India   \n",
       "4       Looking For Senior Data Scientist For Denave   \n",
       "5                             Lead Assistant Manager   \n",
       "6             CogniTensor - Data Scientist (1-2 yrs)   \n",
       "7  Data Scientist | Data Engineer | Machine Learning   \n",
       "8       Data Scientist - Machine Learning (5-14 yrs)   \n",
       "9                             Manager Data Scientist   \n",
       "\n",
       "                          Company_info  \\\n",
       "0           Jubilant Foodworks Limited   \n",
       "1                     HCL Technologies   \n",
       "2                               EY GDS   \n",
       "3  Tavant Technologies India Pvt. Ltd.   \n",
       "4                Denave India Pvt Ltd.   \n",
       "5                          EXL Service   \n",
       "6                         CHT Sapiense   \n",
       "7           Pitney Bowes India Pvt ltd   \n",
       "8                                Zyoin   \n",
       "9                 Ameriprise Financial   \n",
       "\n",
       "                                            location  \n",
       "0                                              Noida  \n",
       "1                                   Delhi NCR, Noida  \n",
       "2                   Bengaluru/Bangalore, Noida, Pune  \n",
       "3  Bengaluru/Bangalore, Hyderabad/Secunderabad, N...  \n",
       "4                                              Noida  \n",
       "5  Noida, Gurgaon/Gurugram, Bengaluru/Bangalore +...  \n",
       "6                                              Noida  \n",
       "7                                              Noida  \n",
       "8                         Bengaluru/Bangalore, Noida  \n",
       "9                                              Noida  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title of the job \n",
    "job_title = []\n",
    "title = driver.find_elements_by_xpath('//a[@class=\"title noclick\"]')\n",
    "for i in title:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "\n",
    "#Description \n",
    "company_info = []\n",
    "info = driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in info:\n",
    "    company_info.append(i.text)\n",
    "\n",
    "\n",
    "#location\n",
    "location = []\n",
    "loc =driver.find_elements_by_xpath('//div[@class=\"entity loc\"]')\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "\n",
    "job = pd.DataFrame({})\n",
    "job['Title'] = job_title\n",
    "job['Company_info'] = company_info\n",
    "job['location']= location[1:11]\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740c765",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c84f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\harsh\\Desktop\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#sending the url\n",
    "url =' https://www.ambitionbox.com/'\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60713180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the salaries web element\n",
    "sal_we = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "sal_we.click()\n",
    "\n",
    "#getting the web elements of the search for job profile\n",
    "search_p = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "search_p.send_keys('Data Scientist')\n",
    "search_p.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0168b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "submit.click()\n",
    "submit_ = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "submit_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7033091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹ 17.7L', '₹ 15.0L', '₹ 9.8L', '₹ 11.0L', '₹ 9.5L', '₹ 9.0L', '₹ 8.3L', '₹ 10.0L', '₹ 8.5L', '₹ 5.8L']\n",
      "['₹ 35.0L', '₹ 25.5L', '₹ 20.0L', '₹ 21.3L', '₹ 22.0L', '₹ 18.5L', '₹ 20.5L', '₹ 21.0L', '₹ 15.0L', '₹ 24.0L']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Minimum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n3 yrs exp</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 25 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>₹ 20.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n2 yrs exp</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 25 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 75 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n2-4 yrs exp</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 30 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "      <td>₹ 14.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 51 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n2-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 13.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 43 salaries</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_name           Description  \\\n",
       "0                   Walmart  based on 10 salaries   \n",
       "1                  Ab Inbev  based on 25 salaries   \n",
       "2                        ZS  based on 13 salaries   \n",
       "3                     Optum  based on 25 salaries   \n",
       "4         Fractal Analytics  based on 75 salaries   \n",
       "5           Tiger Analytics  based on 30 salaries   \n",
       "6              UnitedHealth  based on 51 salaries   \n",
       "7                   Verizon  based on 14 salaries   \n",
       "8  Ganit Business Solutions  based on 13 salaries   \n",
       "9                  Ericsson  based on 43 salaries   \n",
       "\n",
       "                         Experience Minimum_salary Maximum_salary  \\\n",
       "0    Data Scientist\\n . \\n3 yrs exp        ₹ 17.7L        ₹ 35.0L   \n",
       "1  Data Scientist\\n . \\n3-4 yrs exp        ₹ 15.0L        ₹ 25.5L   \n",
       "2    Data Scientist\\n . \\n2 yrs exp         ₹ 9.8L        ₹ 20.0L   \n",
       "3  Data Scientist\\n . \\n3-4 yrs exp        ₹ 11.0L        ₹ 21.3L   \n",
       "4  Data Scientist\\n . \\n2-4 yrs exp         ₹ 9.5L        ₹ 22.0L   \n",
       "5  Data Scientist\\n . \\n3-4 yrs exp         ₹ 9.0L        ₹ 18.5L   \n",
       "6  Data Scientist\\n . \\n2-4 yrs exp         ₹ 8.3L        ₹ 20.5L   \n",
       "7    Data Scientist\\n . \\n4 yrs exp        ₹ 10.0L        ₹ 21.0L   \n",
       "8    Data Scientist\\n . \\n4 yrs exp         ₹ 8.5L        ₹ 15.0L   \n",
       "9  Data Scientist\\n . \\n3-4 yrs exp         ₹ 5.8L        ₹ 24.0L   \n",
       "\n",
       "  Average_salary  \n",
       "0        ₹ 28.7L  \n",
       "1        ₹ 20.2L  \n",
       "2        ₹ 15.5L  \n",
       "3        ₹ 15.1L  \n",
       "4        ₹ 15.1L  \n",
       "5        ₹ 14.2L  \n",
       "6        ₹ 13.8L  \n",
       "7        ₹ 12.7L  \n",
       "8        ₹ 12.4L  \n",
       "9        ₹ 11.9L  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name of the company\n",
    "company_name = []\n",
    "name = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "\n",
    "for i in name:\n",
    "    anchor = i.find_elements_by_tag_name('a')\n",
    "    for j in anchor:\n",
    "        company_name.append(j.text)\n",
    "\n",
    "#description\n",
    "descrip = []\n",
    "des = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "\n",
    "for i in name:\n",
    "    spa = i.find_elements_by_tag_name('span')\n",
    "    for j in spa:\n",
    "        descrip.append(j.text)\n",
    "\n",
    "#yrs of exp\n",
    "exp = []\n",
    "e = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "\n",
    "for i in e:\n",
    "     exp.append(i.text)\n",
    "\n",
    "\n",
    "#minimal salary\n",
    "salary = []\n",
    "min_sal = []\n",
    "max_sal =[]\n",
    "m = driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in m:\n",
    "    salary.append(i.text)\n",
    "\n",
    "min_sal = salary[0:20:2]\n",
    "max_sal =salary[1:20:2]\n",
    "\n",
    "#average salary\n",
    "avg_sal =[]\n",
    "a = driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for i in a:\n",
    "    avg_sal.append(i.text)\n",
    "\n",
    "\n",
    "# creating the dataframe\n",
    "\n",
    "salary_ = pd.DataFrame({'Company_name':company_name,\n",
    "           'Description':descrip,\n",
    "           'Experience':exp,\n",
    "           'Minimum_salary':min_sal,\n",
    "           'Maximum_salary':max_sal,\n",
    "           'Average_salary':avg_sal})\n",
    "salary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cebb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
